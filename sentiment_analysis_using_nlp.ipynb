{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "20GL9PlKelPj"
      },
      "outputs": [],
      "source": [
        "import requests\n",
        "from bs4 import BeautifulSoup\n",
        "from textblob import TextBlob\n",
        "import spacy\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Load spaCy model\n",
        "nlp = spacy.load(\"en_core_web_sm\")\n",
        "\n",
        "# Function to scrape website text\n",
        "def scrape_website_text(url):\n",
        "    \"\"\"\n",
        "    Fetch HTML content from the given URL, parse it with BeautifulSoup,\n",
        "    then return the combined text from all <p> tags.\n",
        "    \"\"\"\n",
        "    try:\n",
        "        response = requests.get(url, timeout=10)\n",
        "        response.raise_for_status()  # Raise an error if status code != 200\n",
        "    except requests.exceptions.RequestException as e:\n",
        "        print(f\"Error fetching {url}: {e}\")\n",
        "        return \"\"\n",
        "\n",
        "    soup = BeautifulSoup(response.text, \"html.parser\")\n",
        "\n",
        "    # Extract text from all <p> tags\n",
        "    paragraphs = soup.find_all(\"p\")\n",
        "    text_content = \" \".join([p.get_text(strip=True) for p in paragraphs])\n",
        "\n",
        "    return text_content\n",
        "\n",
        "# Function to perform sentiment analysis using TextBlob\n",
        "def analyze_sentiment(text):\n",
        "    \"\"\"\n",
        "    Perform sentiment analysis on the text.\n",
        "    Returns a float value indicating sentiment polarity.\n",
        "    \"\"\"\n",
        "    blob = TextBlob(text)\n",
        "    return blob.sentiment.polarity\n",
        "\n",
        "# Function to extract noun phrases using spaCy\n",
        "def extract_noun_phrases(text):\n",
        "    \"\"\"\n",
        "    Extract noun phrases from the text using spaCy.\n",
        "    Returns a list of noun phrases.\n",
        "    \"\"\"\n",
        "    doc = nlp(text)\n",
        "    return [chunk.text for chunk in doc.noun_chunks]\n",
        "\n",
        "# Function to analyze specific keywords and perform sentiment analysis\n",
        "def analyze_keywords_with_sentiment(text, keywords):\n",
        "    \"\"\"\n",
        "    Analyze keywords in the text and perform sentiment analysis on sentences containing those keywords.\n",
        "    Returns a dictionary of keywords and their corresponding sentiment.\n",
        "    \"\"\"\n",
        "    keyword_sentiment = {}\n",
        "\n",
        "    # Extract sentences\n",
        "    sentences = text.split('. ')\n",
        "\n",
        "    for keyword in keywords:\n",
        "        keyword_sentences = [sentence for sentence in sentences if keyword.lower() in sentence.lower()]\n",
        "        if keyword_sentences:\n",
        "            sentiment_values = [analyze_sentiment(sentence) for sentence in keyword_sentences]\n",
        "            avg_sentiment = sum(sentiment_values) / len(sentiment_values) if sentiment_values else 0\n",
        "            keyword_sentiment[keyword] = avg_sentiment\n",
        "\n",
        "    return keyword_sentiment\n",
        "\n",
        "# Function to visualize sentiment of keywords using a bar chart\n",
        "def visualize_sentiment(keyword_sentiment):\n",
        "    \"\"\"\n",
        "    Visualize the sentiment analysis results using a bar chart.\n",
        "    \"\"\"\n",
        "    keywords = list(keyword_sentiment.keys())\n",
        "    sentiments = list(keyword_sentiment.values())\n",
        "\n",
        "    # Create a bar chart\n",
        "    plt.figure(figsize=(10, 6))\n",
        "    plt.bar(keywords, sentiments, color=['lightgreen' if sentiment > 0 else 'red' for sentiment in sentiments])\n",
        "    plt.xlabel('Keywords')\n",
        "    plt.ylabel('Sentiment Score')\n",
        "    plt.title('Sentiment Analysis for Keywords in Reviews')\n",
        "    plt.show()\n",
        "\n",
        "# Main function to execute the scraping, analysis, and visualization\n",
        "def scrape_and_analyze(url, keywords):\n",
        "    \"\"\"\n",
        "    Orchestrates scraping the URL and performing sentiment analysis on specific keywords.\n",
        "    Visualizes the sentiment analysis results.\n",
        "    \"\"\"\n",
        "    # Step 1: Scrape text\n",
        "    raw_text = scrape_website_text(url)\n",
        "    if not raw_text:\n",
        "        return None\n",
        "\n",
        "    # Step 2: Perform NLP (extract noun phrases)\n",
        "    noun_phrases = extract_noun_phrases(raw_text)\n",
        "\n",
        "    # Step 3: Perform sentiment analysis for specified keywords\n",
        "    keyword_sentiment = analyze_keywords_with_sentiment(raw_text, keywords)\n",
        "\n",
        "    # Step 4: Visualize the sentiment for the keywords\n",
        "    visualize_sentiment(keyword_sentiment)\n",
        "\n",
        "    return {\n",
        "        \"url\": url,\n",
        "        \"raw_text\": raw_text,\n",
        "        \"noun_phrases\": noun_phrases,\n",
        "        \"keyword_sentiment\": keyword_sentiment\n",
        "    }\n",
        "\n",
        "# Example usage\n",
        "url = \"https://www.amazon.com/dp/B0DLJ4J78G/ref=fs_a_mbt2_us2\"  # Replace with your target URL\n",
        "keywords = [\"battery\", \"performance\", \"screen\", \"camera\", \"price\" , \"display\", \"weight\" , \"RAM\"]  # List of keywords to analyze\n",
        "\n",
        "result = scrape_and_analyze(url, keywords)\n",
        "\n",
        "# Print the result (optional)\n",
        "if result:\n",
        "    print(\"Sentiment for Keywords:\", result[\"keyword_sentiment\"])\n",
        "\n",
        "\n"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}